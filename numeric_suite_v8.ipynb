{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhnq/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.utils import yaml_load, LOGGER, RANK\n",
    "import onnx\n",
    "from thop import profile\n",
    "from torch.ao.quantization.qconfig import QConfig\n",
    "from ultralytics.nn.modules_quantized import Q_Conv\n",
    "import torchvision\n",
    "from torchvision import models, datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.quantization as quantization\n",
    "import torch.quantization._numeric_suite as ns\n",
    "from torch.ao.quantization import (\n",
    "    default_eval_fn,\n",
    "    default_qconfig,\n",
    "    quantize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizableResNet(\n",
      "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.00818648561835289, zero_point=0, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): Identity()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.006201634649187326, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.03158609941601753, zero_point=51, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.023167304694652557, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.013521037064492702, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.026872174814343452, zero_point=47, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.02623854950070381, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.009454590268433094, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.022116735577583313, zero_point=42, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.01646103523671627, zero_point=64)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.014949643984436989, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.01343428436666727, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.03347558528184891, zero_point=46, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.03362990915775299, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.012336278334259987, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.033084936439991, zero_point=29, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.011953175999224186, zero_point=90)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.01918650232255459, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00954462680965662, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.015005226247012615, zero_point=47, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.015754958614706993, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.005341783631592989, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.017094360664486885, zero_point=51, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.021550370380282402, zero_point=75)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.010784585028886795, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.004518759902566671, zero_point=0, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): Identity()\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.025387253612279892, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (add_relu): QFunctional(\n",
      "        scale=0.021994560956954956, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.04955749586224556, zero_point=48, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "float_model = torchvision.models.quantization.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1, quantize=False)\n",
    "float_model.to('cpu')\n",
    "float_model.eval()\n",
    "float_model.fuse_model()\n",
    "float_model.qconfig = torch.quantization.default_qconfig\n",
    "img_data = [(torch.rand(2, 3, 10, 10, dtype=torch.float), torch.randint(0, 1, (2,), dtype=torch.long)) for _ in range(2)]\n",
    "qmodel = quantize(float_model, default_eval_fn, [img_data], inplace=False)\n",
    "print(qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys of wt_compare_dict:\n",
      "dict_keys(['conv1.weight', 'layer1.0.conv1.weight', 'layer1.0.conv2.weight', 'layer1.1.conv1.weight', 'layer1.1.conv2.weight', 'layer2.0.conv1.weight', 'layer2.0.conv2.weight', 'layer2.0.downsample.0.weight', 'layer2.1.conv1.weight', 'layer2.1.conv2.weight', 'layer3.0.conv1.weight', 'layer3.0.conv2.weight', 'layer3.0.downsample.0.weight', 'layer3.1.conv1.weight', 'layer3.1.conv2.weight', 'layer4.0.conv1.weight', 'layer4.0.conv2.weight', 'layer4.0.downsample.0.weight', 'layer4.1.conv1.weight', 'layer4.1.conv2.weight', 'fc._packed_params._packed_params'])\n",
      "\n",
      "keys of wt_compare_dict entry for conv1's weight:\n",
      "dict_keys(['float', 'quantized'])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64, 3, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "wt_compare_dict = ns.compare_weights(float_model.state_dict(), qmodel.state_dict())\n",
    "\n",
    "print('keys of wt_compare_dict:')\n",
    "print(wt_compare_dict.keys())\n",
    "\n",
    "print(\"\\nkeys of wt_compare_dict entry for conv1's weight:\")\n",
    "print(wt_compare_dict['conv1.weight'].keys())\n",
    "print(wt_compare_dict['conv1.weight']['float'].shape)\n",
    "print(wt_compare_dict['conv1.weight']['quantized'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights_qconv(conv, qconv):\n",
    "    state_dict_conv = conv.state_dict()\n",
    "    state_dict_qconv = qconv.state_dict()\n",
    "    state_dict_qconv['conv.weight'] = state_dict_conv['conv.weight']\n",
    "    for bn_key in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "        state_dict_qconv[f'bn.{bn_key}'] = state_dict_conv[f'bn.{bn_key}']\n",
    "    for attr_name in dir(conv):\n",
    "        attr_value = getattr(conv, attr_name)\n",
    "        if not callable(attr_value) and '_' not in attr_name:\n",
    "            setattr(qconv, attr_name, attr_value)\n",
    "    qconv.load_state_dict(state_dict_qconv)\n",
    "    \n",
    "def replace_conv_with_qconv_v2_ptq(module):\n",
    "    for name, child_module in module.named_children():\n",
    "        if isinstance(child_module, Detect):\n",
    "            continue\n",
    "        elif isinstance(child_module, Conv):\n",
    "            # Replace C2f with C2f_v2 while preserving its parameters\n",
    "            conv2d = child_module.conv\n",
    "            (c1, c2, k, s, p, g, d, act) = (conv2d.in_channels, conv2d.out_channels, conv2d.kernel_size, \n",
    "                                conv2d.stride, conv2d.padding, conv2d.groups, conv2d.dilation[0], child_module.act)\n",
    "            qconv = Q_Conv(c1, c2, k, s, p=p, g=g, d=d, act=act)\n",
    "            qconfig = QConfig(activation=torch.quantization.QuantStubConfig(dtype=\"float\"),\n",
    "                                weight=torch.quantization.QuantStubConfig(dtype=\"float\"),\n",
    "                                qscheme=\"float16\",\n",
    "                            )\n",
    "\n",
    "            # qconfig = quantization.get_default_qat_qconfig()\n",
    "            qconv.qconfig = qconfig\n",
    "            setattr(module, name, qconv)\n",
    "            transfer_weights_qconv(child_module, qconv) \n",
    "            qconv.eval()\n",
    "            if not isinstance(act, nn.ReLU):\n",
    "                torch.quantization.fuse_modules(qconv, [['conv', 'bn']], inplace=True)\n",
    "                qconv.forward = forward.__get__(qconv)\n",
    "            else:\n",
    "                torch.quantization.fuse_modules(qconv, [['conv', 'bn', 'act']], inplace=True)\n",
    "        else:\n",
    "            replace_conv_with_qconv_v2_ptq(child_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhnq/miniconda3/envs/py310/lib/python3.10/site-packages/torch/jit/_trace.py:753: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "script_model = torch.jit.load(\"asset/trained_model/UA-DETRAC/v8s_relu_DETRAC.torchscript\")\n",
    "\n",
    "# Convert the script model to a regular PyTorch model\n",
    "if isinstance(script_model, torch.jit.ScriptModule):\n",
    "    # If the loaded model is a ScriptModule, invoke it to get the underlying nn.Module\n",
    "    model = script_model.eval()\n",
    "else:\n",
    "    # If the loaded model is already an nn.Module, use it directly\n",
    "    model = script_model\n",
    "\n",
    "model = torch.jit.trace(model, torch.randn(1, 3, 640, 640))\n",
    " \n",
    "# model2 = YOLO('yolov8s_relu.pt')\n",
    "# print(model2.model.model)\n",
    "\n",
    "# replace_conv_with_qconv_v2_ptq(model2.model)\n",
    "# torch.quantization.prepare(model2.model, inplace=True)\n",
    "# torch.quantization.convert(model2.model, inplace=True)\n",
    "\n",
    "# example_input = torch.randn(1, 3, 640, 640)\n",
    "# model2.model(example_input)\n",
    "# # scripted_model = torch.jit.script(model2.model)\n",
    "# traced_model = torch.jit.trace(model2.model, example_input, strict=False)\n",
    "\n",
    "# traced_model.save('tmp.torchscript')\n",
    "# float_model = torch.jit.load('tmp.torchscript')\n",
    "\n",
    "with open(\"yolo_model.txt\", \"w\") as file:\n",
    "    for key in model.state_dict().keys():\n",
    "        file.write(key + '\\n')\n",
    "\n",
    "# wt_compare_dict = ns.compare_weights(model.state_dict(), float_model.state_dict())\n",
    "\n",
    "# print('keys of wt_compare_dict:')\n",
    "# print(wt_compare_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
